{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "\n",
    "# reference_image = cv2.imread(r'dataset/dhruv_reference.jpg')\n",
    "reference_image = cv2.imread(r'dataset/amit_advanced.jpg')\n",
    "threshold = 0.1\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "reference_results = pose.process(cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "reference_landmarks = []\n",
    "if reference_results.pose_landmarks:\n",
    "    for i, landmark in enumerate(reference_results.pose_landmarks.landmark):\n",
    "        reference_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "# input_video_path = r'dataset/videos/pcc.mp4'\n",
    "input_video_path = r'dataset/test.mp4'\n",
    "# input_video = cv2.VideoCapture(0)\n",
    "input_video = cv2.VideoCapture(input_video_path)\n",
    "output_video_path = 'advancedvriksh/overallmix.mp4'  # Choose your desired output file name\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "fps = int(input_video.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Create a VideoWriter object to save the output video.\n",
    "output_video = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "keypoint_labels = {\n",
    "    \"Perfect\": \"Perfect! Keep Going :)\",\n",
    "    \"HandsNotAtRightPosition\": \"Hands not at right position\",\n",
    "    \"HandsNotAt90\": \"Hands not at 90 degree\",\n",
    "    \"LegsNotTriangle\": \"Legs not triangle\",\n",
    "    \"Hands_legs_wrong\": \"Hands and leg both wrong\",\n",
    "    \"LegDown\": \"Leg Down\",\n",
    "    \"Idle\": \"Idle, please perform asana\",\n",
    "    \"BentRight\": \"Bent right, \\nstraighten yourself\",\n",
    "    \"BentLeft\": \"Bent left, \\nstraighten yourself\",\n",
    "    \"BentForward\": \"Bent forward, straighten yourself\",\n",
    "    \"WrongPosture\" : \"Straighten yourself\"\n",
    "}\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_results = pose.process(frame_rgb)\n",
    "\n",
    "    frame_landmarks = []\n",
    "    if frame_results.pose_landmarks:\n",
    "        for i, landmark in enumerate(frame_results.pose_landmarks.landmark):\n",
    "            frame_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "    if len(frame_landmarks) > 0 and len(reference_landmarks) > 0:\n",
    "        initial_offset = np.array(reference_landmarks[0][:2]) - np.array(frame_landmarks[0][:2])\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    leg_down = False\n",
    "    hands_not_at_right_position = False\n",
    "    hands_not_at_90 = False\n",
    "    bent_right = False\n",
    "    bent_left = False\n",
    "    bent_forward = False\n",
    "    LegsNotTriangle = False\n",
    "\n",
    "    #DIFFERENT\n",
    "    right_shoulder_y = None\n",
    "    left_shoulder_y = None\n",
    "\n",
    "\n",
    "    for frame_landmark in frame_landmarks:\n",
    "        frame_point = frame_landmark[:2]\n",
    "        frame_keypoint_number = frame_landmark[2]\n",
    "\n",
    "        if frame_keypoint_number == 11:  # Left Shoulder\n",
    "            left_shoulder_y = frame_point[1]\n",
    "        elif frame_keypoint_number == 12:  # Right Shoulder\n",
    "            right_shoulder_y = frame_point[1]\n",
    "        elif frame_keypoint_number == 13:  # Left Elbow\n",
    "            left_elbow_y = frame_point[1]\n",
    "        elif frame_keypoint_number == 14:  # Right Elbow\n",
    "            right_elbow_y = frame_point[1]\n",
    "        \n",
    "        adjusted_left_shoulder_point = (reference_landmarks[11][0] - initial_offset[0], reference_landmarks[11][1] - initial_offset[1])\n",
    "        adjusted_right_shoulder_point = (reference_landmarks[12][0] - initial_offset[0], reference_landmarks[12][1] - initial_offset[1])\n",
    "\n",
    "        # Obtain y-coordinates of the adjusted reference frame for left and right shoulders\n",
    "        adjusted_left_shoulder_y = adjusted_left_shoulder_point[1]\n",
    "        adjusted_right_shoulder_y = adjusted_right_shoulder_point[1]\n",
    "\n",
    "        adjusted_reference_point = (reference_landmarks[frame_keypoint_number][0] - initial_offset[0], reference_landmarks[frame_keypoint_number][1] - initial_offset[1])\n",
    "        distance = calculate_distance(adjusted_reference_point, frame_point)\n",
    "        \n",
    "\n",
    "        \n",
    "        if distance < threshold:\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "        else:\n",
    "            \n",
    "            if frame_keypoint_number in [28, 30, 32] or frame_keypoint_number in [27, 29, 31] or frame_keypoint_number == 25 or frame_keypoint_number == 26:\n",
    "                leg_down = True\n",
    "            if frame_keypoint_number == 13 or frame_keypoint_number == 14:\n",
    "                hands_not_at_90 = True\n",
    "            if frame_keypoint_number in [16, 18, 20, 22] or frame_keypoint_number in [15, 17, 19, 21]:\n",
    "                hands_not_at_right_position = True\n",
    "            if frame_keypoint_number == 11:\n",
    "                bent_left = True\n",
    "            if frame_keypoint_number == 12:\n",
    "                bent_right = True\n",
    "                \n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    if bent_left :\n",
    "            label = keypoint_labels[\"BentLeft\"]\n",
    "    elif bent_right :\n",
    "        label = keypoint_labels[\"BentRight\"]\n",
    "    elif leg_down:\n",
    "        if hands_not_at_right_position:\n",
    "            if not hands_not_at_90:\n",
    "                label = keypoint_labels[\"Idle\"]\n",
    "            else:\n",
    "                label = keypoint_labels[\"Hands_legs_wrong\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"LegDown\"]\n",
    "    elif hands_not_at_90:\n",
    "        label = keypoint_labels[\"HandsNotAt90\"]\n",
    "    elif hands_not_at_right_position:\n",
    "        label = keypoint_labels[\"HandsNotAtRightPosition\"]\n",
    "    else:\n",
    "        label = keypoint_labels[\"Perfect\"]\n",
    "\n",
    "    label_lines = label.split('\\n')\n",
    "    for i, line in enumerate(label_lines):\n",
    "        cv2.putText(frame_copy, line, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    output_video.write(frame_copy)\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "input_video.release()\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "advanced - live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "\n",
    "# reference_image = cv2.imread(r'dataset/dhruv_reference.jpg')\n",
    "reference_image = cv2.imread(r'dataset/amit_advanced.jpg')\n",
    "\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "reference_results = pose.process(cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "reference_landmarks = []\n",
    "if reference_results.pose_landmarks:\n",
    "    for i, landmark in enumerate(reference_results.pose_landmarks.landmark):\n",
    "        reference_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "# input_video_path = r'dataset/videos/pcd.mp4'\n",
    "input_video_path = r'dataset/test_advanced.mp4'\n",
    "input_video = cv2.VideoCapture(input_video_path)\n",
    "# input_video = cv2.VideoCapture(input_video_path)\n",
    "output_video_path = 'advancedvriksh/overallmix.mp4'  # Choose your desired output file name\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "fps = int(input_video.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Create a VideoWriter object to save the output video.\n",
    "output_video = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "keypoint_labels = {\n",
    "    \"Perfect\": \"Perfect! \\nKeep Going :)\",\n",
    "    \"HandsNotAtRightPosition\": \"Hands not at right position\",\n",
    "    \"HandsNotAbove\": \"Raise your \\nhands over head\", #elbow and eye\n",
    "    \"LegsInTriangle\": \"Raise your sole above your knee\", #index foot and knee\n",
    "    \"Hands_legs_wrong\": \"Hands and leg both wrong\",\n",
    "    \"LegDown\": \"Leg Down\",\n",
    "    \"Idle\": \"Idle, please perform asana\",\n",
    "    \"BentRight\": \"Bent right, \\nstraighten yourself\",\n",
    "    \"BentLeft\": \"Bent left, \\nstraighten yourself\",\n",
    "    \"BentForward\": \"Bent forward, straighten yourself\"\n",
    "}\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_results = pose.process(frame_rgb)\n",
    "\n",
    "    frame_landmarks = []\n",
    "    if frame_results.pose_landmarks:\n",
    "        for i, landmark in enumerate(frame_results.pose_landmarks.landmark):\n",
    "            frame_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "    if len(frame_landmarks) > 0 and len(reference_landmarks) > 0:\n",
    "        initial_offset = np.array(reference_landmarks[0][:2]) - np.array(frame_landmarks[0][:2])\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    leg_down = False\n",
    "    hands_not_at_right_position = False\n",
    "    hands_not_above = False\n",
    "    bent_right = False\n",
    "    bent_left = False\n",
    "    bent_forward = False\n",
    "    LegsNotTriangle = False\n",
    "\n",
    "    #DIFFERENT\n",
    "    right_shoulder_y = None\n",
    "    left_shoulder_y = None\n",
    "    # left_elbow_y = None\n",
    "    # right_elbow_y = None\n",
    "    # left_eye_y = None\n",
    "    # right_eye_y = None\n",
    "\n",
    "\n",
    "    for frame_landmark in frame_landmarks:\n",
    "        frame_point = frame_landmark[:2]\n",
    "        frame_keypoint_number = frame_landmark[2]\n",
    "\n",
    "        if frame_keypoint_number == 11:  # Left Shoulder\n",
    "            left_shoulder_y = frame_point[1]\n",
    "        if frame_keypoint_number == 12:  # Right Shoulder\n",
    "            right_shoulder_y = frame_point[1]\n",
    "        if frame_keypoint_number == 13:  # Left Elbow\n",
    "            left_elbow_y = frame_point[1]\n",
    "        if frame_keypoint_number == 14:  # Right Elbow\n",
    "            right_elbow_y = frame_point[1]\n",
    "        if frame_keypoint_number == 2:  # Left eye\n",
    "            left_eye_y = frame_point[1]\n",
    "        if frame_keypoint_number == 5:  # Right eye\n",
    "            right_eye_y = frame_point[1]\n",
    "        \n",
    "        adjusted_left_shoulder_point = (reference_landmarks[11][0] - initial_offset[0], reference_landmarks[11][1] - initial_offset[1])\n",
    "        adjusted_right_shoulder_point = (reference_landmarks[12][0] - initial_offset[0], reference_landmarks[12][1] - initial_offset[1])\n",
    "\n",
    "        # Obtain y-coordinates of the adjusted reference frame for left and right shoulders\n",
    "        adjusted_left_shoulder_y = adjusted_left_shoulder_point[1]\n",
    "        adjusted_right_shoulder_y = adjusted_right_shoulder_point[1]\n",
    "\n",
    "        adjusted_reference_point = (reference_landmarks[frame_keypoint_number][0] - initial_offset[0], reference_landmarks[frame_keypoint_number][1] - initial_offset[1])\n",
    "        distance = calculate_distance(adjusted_reference_point, frame_point)\n",
    "        threshold = 0.1\n",
    "\n",
    "        \n",
    "        if distance < threshold:\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "        else:\n",
    "            \n",
    "            if frame_keypoint_number in [28, 30, 32] or frame_keypoint_number in [27, 29, 31] or frame_keypoint_number == 25 or frame_keypoint_number == 26:\n",
    "                leg_down = True\n",
    "            if frame_keypoint_number == 13 or frame_keypoint_number == 14:        \n",
    "                hands_not_above = True\n",
    "            if frame_keypoint_number in [16, 18, 20, 22] or frame_keypoint_number in [15, 17, 19, 21]:\n",
    "                hands_not_at_right_position = True\n",
    "            if frame_keypoint_number in [11] or frame_keypoint_number in [12]:\n",
    "                if left_shoulder_y is not None and right_shoulder_y is not None:\n",
    "                    if left_shoulder_y < right_shoulder_y:\n",
    "                        bent_right = True\n",
    "                    elif left_shoulder_y > right_shoulder_y:\n",
    "                        bent_left = True\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    if bent_left:\n",
    "        label = keypoint_labels[\"BentLeft\"]\n",
    "    elif bent_right:\n",
    "        label = keypoint_labels[\"BentRight\"]\n",
    "    elif leg_down:\n",
    "        if hands_not_at_right_position:\n",
    "            label = keypoint_labels[\"Idle\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"LegDown\"]\n",
    "    elif hands_not_above:\n",
    "        label = keypoint_labels[\"HandsNotAbove\"]\n",
    "    elif not hands_not_above and hands_not_at_right_position:\n",
    "        label = keypoint_labels[\"HandsNotAtRightPosition\"]\n",
    "    else:\n",
    "        label = keypoint_labels[\"Perfect\"]\n",
    "\n",
    "    label_lines = label.split('\\n')\n",
    "    for i, line in enumerate(label_lines):\n",
    "        cv2.putText(frame_copy, line, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    output_video.write(frame_copy)\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "input_video.release()\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "masti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nose: (0.5033059120178223, 0.15204253792762756)\n",
      "Left Eye Inner: (0.5274533629417419, 0.13302761316299438)\n",
      "Left Eye: (0.5428935289382935, 0.13307830691337585)\n",
      "Left Eye Outer: (0.5525503754615784, 0.1336582899093628)\n",
      "Right Eye Inner: (0.4888327121734619, 0.13416564464569092)\n",
      "Right Eye: (0.47721368074417114, 0.13473135232925415)\n",
      "Right Eye Outer: (0.4676058292388916, 0.1355954110622406)\n",
      "Left Ear: (0.5682936906814575, 0.14232903718948364)\n",
      "Right Ear: (0.4566885828971863, 0.1437881588935852)\n",
      "Mouth Left: (0.5281562209129333, 0.17326602339744568)\n",
      "Mouth Right: (0.48537951707839966, 0.1729699671268463)\n",
      "Left Shoulder: (0.6558054685592651, 0.26218825578689575)\n",
      "Right Shoulder: (0.37646496295928955, 0.25620216131210327)\n",
      "Left Elbow: (0.7262104153633118, 0.3765597939491272)\n",
      "Right Elbow: (0.2654138505458832, 0.3639928698539734)\n",
      "Left Wrist: (0.5005074143409729, 0.37100186944007874)\n",
      "Right Wrist: (0.42679333686828613, 0.3737330138683319)\n",
      "Left Pinky: (0.4756017327308655, 0.3418465256690979)\n",
      "Right Pinky: (0.4546295702457428, 0.34820640087127686)\n",
      "Left Index: (0.4857139587402344, 0.3342379629611969)\n",
      "Right Index: (0.4633328914642334, 0.34115171432495117)\n",
      "Left Thumb: (0.4909091889858246, 0.3425120711326599)\n",
      "Right Thumb: (0.4575108289718628, 0.3494567573070526)\n",
      "Left Hip: (0.535621166229248, 0.48950380086898804)\n",
      "Right Hip: (0.4024721086025238, 0.4711208939552307)\n",
      "Left Knee: (0.5094426870346069, 0.6360471844673157)\n",
      "Right Knee: (0.18324805796146393, 0.5479189157485962)\n",
      "Left Ankle: (0.48842835426330566, 0.7448459267616272)\n",
      "Right Ankle: (0.43441593647003174, 0.5924702882766724)\n",
      "Left Heel: (0.4858749210834503, 0.7534970045089722)\n",
      "Right Heel: (0.47842884063720703, 0.5826362371444702)\n",
      "Left Foot Index: (0.4797332286834717, 0.8108986616134644)\n",
      "Right Foot Index: (0.485650897026062, 0.6660621166229248)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize mediapipe pose class.\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Create a function to calculate Euclidean distance between two points.\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "\n",
    "# Load the reference image.\n",
    "reference_image = cv2.imread(r'dataset/dhruv_reference.jpg')\n",
    "\n",
    "# Create a Pose object for reference image processing.\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "# Process the reference image.\n",
    "reference_results = pose.process(cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# Retrieve the landmarks from the reference image.\n",
    "reference_landmarks = []\n",
    "if reference_results.pose_landmarks:\n",
    "    for i, landmark in enumerate(reference_results.pose_landmarks.landmark):\n",
    "        reference_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "# Define a dictionary to map keypoint numbers to body parts.\n",
    "keypoint_labels = {\n",
    "    0: \"Nose\",\n",
    "    1: \"Left Eye Inner\",\n",
    "    2: \"Left Eye\",\n",
    "    3: \"Left Eye Outer\",\n",
    "    4: \"Right Eye Inner\",\n",
    "    5: \"Right Eye\",\n",
    "    6: \"Right Eye Outer\",\n",
    "    7: \"Left Ear\",\n",
    "    8: \"Right Ear\",\n",
    "    9: \"Mouth Left\",\n",
    "    10: \"Mouth Right\",\n",
    "    11: \"Left Shoulder\",\n",
    "    12: \"Right Shoulder\",\n",
    "    13: \"Left Elbow\",\n",
    "    14: \"Right Elbow\",\n",
    "    15: \"Left Wrist\",\n",
    "    16: \"Right Wrist\",\n",
    "    17: \"Left Pinky\",\n",
    "    18: \"Right Pinky\",\n",
    "    19: \"Left Index\",\n",
    "    20: \"Right Index\",\n",
    "    21: \"Left Thumb\",\n",
    "    22: \"Right Thumb\",\n",
    "    23: \"Left Hip\",\n",
    "    24: \"Right Hip\",\n",
    "    25: \"Left Knee\",\n",
    "    26: \"Right Knee\",\n",
    "    27: \"Left Ankle\",\n",
    "    28: \"Right Ankle\",\n",
    "    29: \"Left Heel\",\n",
    "    30: \"Right Heel\",\n",
    "    31: \"Left Foot Index\",\n",
    "    32: \"Right Foot Index\"\n",
    "}\n",
    "\n",
    "# Print the keypoints and their corresponding body parts.\n",
    "for landmark in reference_landmarks:\n",
    "    x, y, keypoint_number = landmark\n",
    "    body_part = keypoint_labels[keypoint_number]\n",
    "    print(f\"{body_part}: ({x}, {y})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "\n",
    "reference_image = cv2.imread(r'dataset/dhruv_reference.jpg')\n",
    "# reference_image = cv2.imread(r'dataset/amit_reference.jpg')\n",
    "\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "reference_results = pose.process(cv2.cvtColor(reference_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "reference_landmarks = []\n",
    "if reference_results.pose_landmarks:\n",
    "    for i, landmark in enumerate(reference_results.pose_landmarks.landmark):\n",
    "        reference_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "input_video_path = r'dataset/videos/pcd.mp4'\n",
    "# input_video_path = r'dataset/test.mp4'\n",
    "# input_video = cv2.VideoCapture(0)\n",
    "input_video = cv2.VideoCapture(input_video_path)\n",
    "keypoint_labels = {\n",
    "    \"Perfect\": \"Perfect! Keep Going :)\",\n",
    "    \"HandsNotAtRightPosition\": \"Hands not at right position\",\n",
    "    \"HandsNotAt90\": \"Hands not at 90 degree\",\n",
    "    \"LegsNotTriangle\": \"Legs not triangle\",\n",
    "    \"Hands_legs_wrong\": \"Hands and leg both wrong\",\n",
    "    \"LegDown\": \"Leg Down\",\n",
    "    \"Idle\": \"Idle, please perform asana\",\n",
    "    \"BentRight\": \"Bent right, \\nstraighten yourself\",\n",
    "    \"BentLeft\": \"Bent left, \\nstraighten yourself\",\n",
    "    \"BentForward\": \"Bent forward, straighten yourself\"\n",
    "}\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_results = pose.process(frame_rgb)\n",
    "\n",
    "    frame_landmarks = []\n",
    "    if frame_results.pose_landmarks:\n",
    "        for i, landmark in enumerate(frame_results.pose_landmarks.landmark):\n",
    "            frame_landmarks.append((landmark.x, landmark.y, i))\n",
    "\n",
    "    if len(frame_landmarks) > 0 and len(reference_landmarks) > 0:\n",
    "        initial_offset = np.array(reference_landmarks[0][:2]) - np.array(frame_landmarks[0][:2])\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    leg_down = False\n",
    "    hands_not_at_right_position = False\n",
    "    hands_not_at_90 = False\n",
    "    bent_right = False\n",
    "    bent_left = False\n",
    "    bent_forward = False\n",
    "    LegsNotTriangle = False\n",
    "\n",
    "    right_shoulder_y = 0.0\n",
    "    left_shoulder_y = 0.0\n",
    "\n",
    "\n",
    "    for frame_landmark in frame_landmarks:\n",
    "        frame_point = frame_landmark[:2]\n",
    "        frame_keypoint_number = frame_landmark[2]\n",
    "\n",
    "        if frame_keypoint_number == 11:\n",
    "            left_shoulder_y = frame_landmark[1]\n",
    "            \n",
    "        if frame_keypoint_number == 12:\n",
    "            right_shoulder_y = frame_landmark[1]\n",
    "            \n",
    "        # if frame_keypoint_number == 11:  # Left Shoulder\n",
    "        #     left_shoulder_y = frame_point[1]\n",
    "        # elif frame_keypoint_number == 12:  # Right Shoulder\n",
    "        #     right_shoulder_y = frame_point[1]\n",
    "        # elif frame_keypoint_number == 13:  # Left Elbow\n",
    "        #     left_elbow_y = frame_point[1]\n",
    "        # elif frame_keypoint_number == 14:  # Right Elbow\n",
    "        #     right_elbow_y = frame_point[1]\n",
    "        \n",
    "        adjusted_left_shoulder_point = (reference_landmarks[11][0] - initial_offset[0], reference_landmarks[11][1] - initial_offset[1])\n",
    "        adjusted_right_shoulder_point = (reference_landmarks[12][0] - initial_offset[0], reference_landmarks[12][1] - initial_offset[1])\n",
    "\n",
    "        # Obtain y-coordinates of the adjusted reference frame for left and right shoulders\n",
    "        adjusted_left_shoulder_y = adjusted_left_shoulder_point[1]\n",
    "        adjusted_right_shoulder_y = adjusted_right_shoulder_point[1]\n",
    "\n",
    "        adjusted_reference_point = (reference_landmarks[frame_keypoint_number][0] - initial_offset[0], reference_landmarks[frame_keypoint_number][1] - initial_offset[1])\n",
    "        distance = calculate_distance(adjusted_reference_point, frame_point)\n",
    "        threshold = 0.1\n",
    "\n",
    "        \n",
    "        if distance < threshold:\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 255, 0), -1)\n",
    "        else:\n",
    "            \n",
    "            if frame_keypoint_number in [28, 30, 32] or frame_keypoint_number in [27, 29, 31] or frame_keypoint_number == 25 or frame_keypoint_number == 26:\n",
    "                leg_down = True\n",
    "            if frame_keypoint_number == 13 or frame_keypoint_number == 14:\n",
    "                hands_not_at_90 = True\n",
    "            if frame_keypoint_number in [16, 18, 20, 22] or frame_keypoint_number in [15, 17, 19, 21]:\n",
    "                hands_not_at_right_position = True\n",
    "            if frame_keypoint_number in [11] or frame_keypoint_number in [12]:\n",
    "                # if left_shoulder_y is not None and right_shoulder_y is not None:\n",
    "                    if left_shoulder_y < right_shoulder_y:\n",
    "                        bent_right = True\n",
    "                    elif left_shoulder_y > right_shoulder_y:\n",
    "                        bent_left = True\n",
    "            cv2.circle(frame_copy, (int(frame_point[0] * frame.shape[1]), int(frame_point[1] * frame.shape[0])), 5, (0, 0, 255), -1)\n",
    "\n",
    "    if bent_left :\n",
    "        label = keypoint_labels[\"BentLeft\"]\n",
    "    elif bent_right :\n",
    "        label = keypoint_labels[\"BentRight\"]\n",
    "    elif leg_down:\n",
    "        if hands_not_at_right_position:\n",
    "            if not hands_not_at_90:\n",
    "                label = keypoint_labels[\"Idle\"]\n",
    "            else:\n",
    "                label = keypoint_labels[\"Hands_legs_wrong\"]\n",
    "        else:\n",
    "            label = keypoint_labels[\"LegDown\"]\n",
    "    elif hands_not_at_90:\n",
    "        label = keypoint_labels[\"HandsNotAt90\"]\n",
    "    elif hands_not_at_right_position:\n",
    "        label = keypoint_labels[\"HandsNotAtRightPosition\"]\n",
    "    else:\n",
    "        label = keypoint_labels[\"Perfect\"]\n",
    "\n",
    "    label_lines = label.split('\\n')\n",
    "    for i, line in enumerate(label_lines):\n",
    "        cv2.putText(frame_copy, line, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Processed Video\", frame_copy)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "input_video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
